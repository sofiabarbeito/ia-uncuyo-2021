<h3>Inteligencia Artificial Débil</h3>
<h6>
La inteligencia artificial fue fundada asumiendo que la IA débil es posible, pero algunos han dicho que no lo es. Pero se puede ver que es posible dependiendo de la definición que le demos. Si la definimos como la búsqueda por el mejor programa para una arquitectura dada, es posible. Pero los filósofos están interesados en el problema de comparar dos arquitecturas, el humano y la máquina.
  </h6>
  <h6>
Alan Turing sugirió que en vez de preguntarnos si las máquinas pueden pensar, deberíamos preguntarnos si pueden pasar una prueba de inteligencia conductual, el Turing Test, en el cual un programa tiene una conversación con un interrogador, y el interrogador tiene que adivinar si la conversación es con una computadora o una persona.
  </h6>
  <h6>
  Turing examinó una gran variedad de posibles objeciones a la posibilidad de estas máquinas inteligentes. Veremos tres de ellas.
</h6>

<h4>El argumento de incapacidad</h4>
<h6>
Hace el reclamo que “una máquina nunca puede hacer X”. Ejemplos de X:
</h6>
<h6>
“ser amable, bello, amigable, tener iniciativa, tener sentido del humor, diferenciar entre el bien y el mal, cometer errores, enamorarse, disfrutar frutillas con crema, hacer que alguien se enamore, aprender de la experiencia, usar las palabras correctamente, …”
</h6>
<h6>
De esto hay muchas cosas fáciles que sabemos que si puede hacer una máquina, como cometer errores. No es sorprendente que las máquinas sean buenas en problemas de combinatoria como jugar al ajedrez. Pero los algoritmos también funcionan a niveles de los humanos en tareas que incluyen juicio humano como “diferenciar entre el bien y el mal” y “aprender de la experiencia”. En 1955, se estudió el procesos de toma de decisiones de expertos para predecir éxitos de estudiantes. Se demostró que con simples algoritmos de aprendizaje estadístico se predicen mejores resultados que los expertos.
Es claro que las computadoras pueden hacer muchas cosas como los humanos o mejor, incluyendo cosas que la gente piensa que requieren un gran conocimiento humano.
</h6>

<h4>La objeción matemática</h4>
<h6>
Es bien sabido que por el trabajo de Turing y de Godel, algunas preguntas matemáticas en principio no se pueden responder por sistemas formales particulares. El teorema de la incompletitud de Godel es el ejemplo más famoso de esto. En resumen, para cualquier sistema axiomático formal F lo suficientemente potente como para hacer aritmética, es posible construir una sentencia Gödel G(F) con las propiedades siguientes:
 </h6>
 <h6>
• G(F) es una sentencia de F, pero no se puede probar dentro de F.
</h6>
<h6>
• Si F es consistente, entonces G(F) es verdadero.
</h6>
<h6>
Filósofos han afirmado que este teorema demuestra que las máquinas son mentalmente inferiores a los hombres, porque las máquinas son sistemas formales limitados por el teorema de la incompletitud, es decir no pueden establecer la verdad de su propia sentencia Gödel, mientras que los hombres no tienen dicha limitación. Esta afirmación tiene tres problemas.
  </h6>
  <h6>
El primero, el teorema de la incompletitud de Gödel se aplica sólo a sistemas formales que son lo suficientemente potentes como para realizar aritmética. Aquí se incluyen las máquinas Turing, y la afirmación en parte se basa en la afirmación de que las computadoras son máquinas de Turing. Esta es una buena aproximación, pero no es del todo verdadera. Aunque las computadoras son finitas, las máquinas de Turing son infinitas, y cualquier computadora se puede describir como un sistema en la lógica proposicional, la cual no está sujeta al teorema de incompletitud de Gödel.
</h6>
<h6>
El segundo, un agente no debería avergonzarse de no poder establecer la verdad de una sentencia aunque otros agentes sí puedan. Por ejemplo, ninguna persona podría calcular la suma de 10 billones de números de 10 dígitos en su vida, en cambio un computador podría hacerlo en segundos. Sin embargo, no vemos esto como una limitación fundamental en la habilidad de pensar del hombre.
  </h6>
<h6>
El tercero, aunque reconozcamos que las computadoras tienen limitaciones sobre lo que pueden demostrar, no existen evidencias de que los hombres sean inmunes ante esas limitaciones.Es imposible demostrar que los hombres no están sujetos al teorema de incompletitud de Gödel, porque cualquier prueba rigurosa contendría una formalización del talento humano declarado como no formalizable. Esta atracción se expresa con argumentos como “debemos asumir nuestra propia consistencia, si el pensamiento puede ser posible”.
</h6>

<h4>El argumento de la informalidad</h4>
<h6>
	Una de las críticas más persistentes e influyentes de la IA como empresa la realizó Turing mediante su “argumento de la informalidad del comportamiento”. En esencia, esta afirmación consiste en que el comportamiento humano es demasiado complejo para poder captarse mediante un simple juego de reglas y que debido a que los computadores no pueden nada más que seguir un conjunto de reglas, no pueden generar un comportamiento tan inteligente como el de los hombres.
  </h6>
<h6>
	El filósofo que ha propuesto principalmente este punto de vista ha sido Hubert Dreyfus, quien elaboró una serie de críticas influyentes a la Inteligencia Artificial. La postura que critican se vino a llamar “Good Old-Fashioned AI” (IA muy anticuada) o GOFAI. Se supone que este término afirma que todo comportamiento inteligente puede ser capturado por un sistema que razona lógicamente a partir de un conjunto de hechos y reglas, los cuales describen el dominio. La crítica de Dreyfus no va en contra de los computadores, sino en contra de una forma en particular de programarlos.
  </h6>
<h6>
	Bajo el punto de vista de Dreyfus, la pericia del hombre incluye el conocimiento de algunas reglas, pero solamente como un contexto holístico dentro del que operan los hombres. Proporciona como ejemplo el comportamiento social adecuado al dar o recibir regalos: “Normalmente se responde simplemente en las circunstancias adecuadas y dando el regalo adecuado”. Al parecer hay que “tener un sentido directo de cómo hay que hacer las cosas y qué esperar”. Es cierto que gran parte de los procesos del pensamiento de una persona que da un regalo se llevan a cabo a un nivel que no está abierto a la introspección por la mente consciente. Sin embargo, esto no significa que no existan los procesos de pensamiento.
  </h6>
<h6>
	Dreyfus propone un proceso de adquisición de pericia en cinco etapas, comenzando con un procesamiento basado en reglas (del tipo propuesto en GOFAI) y terminando con la habilidad de seleccionar las respuestas correctas instantáneamente.
  </h6>
<h6>
	Muchos de los temas que ha tratado Dreyfus, el conocimiento del sentido común básico, el problema de la cualificación, la incertidumbre, aprendizaje, formas compiladas de la toma de decisiones, la importancia de considerar agentes situados y no motores de interferencia incorpóreos, por ahora se han incorporado en el diseño estándar de agentes inteligentes. Bajo nuestro punto de vista, esta es una evidencia del progreso de la IA, y no de su imposibilidad.
</h6>

<h3>Inteligencia Artificial Fuerte</h3>
<h6>
	Muchos filósofos han afirmado que una máquina que pasa el Test de Turing no quiere decir que esté realmente pensando, sería solamente una simulación de la acción de pensar. 
La máquina tiene que ser consciente de sus propias acciones y estados mentales, esto es lo que Turing llama el argumento de la consciencia. Un punto de vista se relaciona realmente con la fenomenología, la máquina tiene que sentir emociones realmente. Otros se centran en la intencionalidad, esto es, en la cuestión de si las creencias, deseos y otras representaciones supuestas de la máquina son de verdad algo que pertenece al mundo real.
  </h6>
<h6>
La respuesta de Turing a esta objeción es interesante. Turing mantiene que la cuestión no está bien definida al decir, “¿Pueden pensar las máquinas?”. Turing dice que “En vez de argumentar constantemente sobre este punto de vista, es usual mantener la convención educada de que todos pensamos".
  </h6>
<h6>

Turing reconoce que la cuestión de la conciencia es difícil, pero niega que sea relevante para la práctica de la IA. Coincidimos en que nos interesa crear programas que se comporten de forma inteligente y no en si alguien los declara reales o simulados. 
</h6>
<h6>
En algunos casos el comportamiento de un artefacto, como los edulcorantes artificiales o la inseminación artificial, es importante, aunque en otros sea el pedigrí del artefacto lo que importa. Lo importante en cada caso parece ser una cuestión de convención. Sin embargo, para las mentes artificiales, no existe una convención, y tenemos que depender de las intuiciones. 
</h6>
<h6>
La teoría del funcionalismo dice que un estado mental es cualquier condición causal inmediata entre la entrada y la salida. Bajo la teoría funcionalista, dos sistemas con procesos causales isomórficos tendrían los mismos estados mentales. Por tanto, un programa informático podría tener los mismos estados mentales que una persona. La suposición es que existe algún nivel de abstracción por debajo del cual no importa una implementación específica; siempre que los procesos sean isomórficos hasta este nivel, tendrán lugar los mismos estados mentales.
</h6>
<h6>
En contraste, la teoría del naturalismo biológico dice que los estados mentales son características emergentes de alto nivel originadas por procesos neurológicos de bajo nivel en las neuronas, y lo que importa son las propiedades de las neuronas. Así pues, los estados mentales no se pueden duplicar justo en la base de algún programa que tiene la misma estructura funcional con el mismo comportamiento de entrada y salida; necesitaríamos que el programa se ejecutara en una arquitectura con la misma potencia causal que las neuronas. La teoría no dice por qué las neuronas tienen esta potencia causal, ni tampoco qué otras instanciaciones físicas podrían tenerla o no.
</h6>

<h3>La ética y los riesgos de desarrollar Inteligencia Artificial</h3>
<h6>
	Ahora nos vamos a concentrar en si deberíamos desarrollar IA. Si es más probable que los efectos de la tecnología de la IA sean más negativos que positivos, sería responsabilidad moral de los trabajadores en su campo redirigir su investigación. Muchas de las nuevas tecnologías han tenido efectos negativos no intencionados. Todos los científicos e ingenieros se enfrentan a consideraciones éticas de cómo deberían actuar en el trabajo, qué proyectos deberían o no deberían hacer, cómo los deberían abordar. Sin embargo, la IA parece que expone problemas nuevos. Examinaremos estos problemas.
</h6>
<h6>
Las personas podrían perder sus trabajos por la automatización. La economía industrial moderna ha llegado a depender en general de los computadores, y selecciona programas de IA en particular. Se podría decir que miles de trabajadores han sido desplazados por programas de IA. Pero hasta ahora, la automatización por medio de la tecnología de la IA ha creado más trabajos de los que ha eliminado, y ha creado puestos de trabajo más interesantes y mejor pagados. Ahora que el programa IA canónico es un “agente inteligente” diseñado para ayudar a un hombre, la pérdida de trabajo preocupa menos que cuando la IA se centraba en los sistemas expertos diseñados para sustituir a los hombres.
</h6>
<h6>
Las personas podrían tener demasiado (o muy poco) tiempo de ocio. Las personas que trabajan en las industrias muy relacionadas con el conocimiento han descubierto que forman parte de un sistema computarizado integrado que funciona 24 horas al día; para mantenerlo se han visto forzados a trabajar durante más horas. En una economía industrial, las recompensas son aproximadamente proporcionales al tiempo invertido; trabajar el 10 por ciento más llevaría a producir un incremento del 10 por ciento en los ingresos. En una economía de la información marcada por la comunicación de un ancho de banda alto y por una reproducción fácil de la propiedad intelectual, existe una gran recompensa por ser ligeramente mejor que la competencia; trabajar un 10 por ciento más podría significar un 100 por 100 de incremento en los ingresos. De forma que todos se sienten más presionados por trabajar más fuerte. La IA incrementa el ritmo de la innovación tecnológica y contribuye así a esta tendencia general, pero la IA también mantiene la promesa de permitirnos ahorrar tiempo y permitir que nuestros agentes automatizados hagan las cosas por un tiempo.
</h6>
<h6>
Las personas podrían perder su sentido de ser únicas. En el libro de Weizenbaum, Computer Power and Human Reason, se señalan algunas de las posibles amenazas que supone la IA para la sociedad. Uno de los argumentos principales es que la investigación en IA hace posible la idea de que los hombres sean autómatas, una idea que produce pérdida de autonomía o incluso de humanidad. La IA, aunque sea una materia de gran éxito, quizá sea por lo menos amenazante para las suposiciones morales de la sociedad del siglo XXI al igual que la teoría de la evolución lo fue para los del siglo XIX.
</h6>
<h6>
Las personas podrían perder algo de sus derechos privados. Weizenbaum también señaló que la tecnología del reconocimiento de voz podría llevar a una intercepción extensa de cableados, y de aquí a la pérdida de las libertades civiles. Algunas personas reconocen que la computarización conduce a la pérdida de privacidad, por ejemplo, el consejero delegado de Sun Microsystems, Scott McNealy ha dicho que «De cualquier forma tenemos privacidad cero. Hay que superarlo». Otros no están de acuerdo. Por ejemplo, el juez Louis Brandeis en 1890 escribió que «La privacidad es el derecho más completo y extenso de todos... el derecho de la personalidad de uno mismo».
</h6>
<h6>
La utilización de sistemas de IA podría llevar a la pérdida de responsabilidad. En la utilización de agentes inteligentes en Internet se han hecho progresos en la incorporación de limitaciones de forma que no pueden, por ejemplo, dañar los archivos de otros usuarios. El problema se magnifica cuando el dinero cambia de manos. Si las transacciones monetarias las realiza un agente inteligente en nombre de alguien, ¿está obligado por las deudas incurridas? ¿Sería posible que un agente inteligente tuviera activos o que realizara compras electrónicas en su propio nombre? Hasta ahora, parece que estas cuestiones no se entienden de forma clara. En nuestro conocimiento, ningún programa ha recibido ningún estado legal como individuo con fines financieros; por el momento, parece que no es razonable hacerlo.
</h6>
<h6>
El éxito de la IA podría significar el fin de la raza humana. Casi cualquier tecnología tiene el potencial de hacer daño si se encuentra en las manos equivocadas, pero con la IA y la robótica, tenemos el problema nuevo de que las manos equivocadas podrían pertenecer a dicha tecnología.
</h6>
<h6>
Si los robots estuvieran diseñados adecuadamente como agentes que adoptan las metas de sus propietarios, probablemente no supondrían una amenaza: los robots que derivan de mayores avances sobre sus diseños actuales, sí que van a servir y no a conquistar. Los hombres utilizan su inteligencia de formas agresivas porque son innatas, por naturaleza. Sin embargo, las máquinas que construimos no tienen que ser innatamente agresivas, a menos que decidamos que así sean. En 1965, I. J. Good escribió:
</h6>
<h6>
Vamos a definir una máquina ultrainteligente como una máquina que puede sobrepasar con mucho todas las actividades intelectuales de cualquier hombre, por muy inteligente que sea. Puesto que el diseño de las máquinas es una de estas actividades intelectuales, una máquina ultrainteligente podría diseñar máquinas incluso mejores; entonces existiría incuestionablemente una “explosión de inteligencia”, y la inteligencia del hombre quedaría bastante atrás.
</h6>
<h6>
La “explosión de inteligencia” también ha sido llamada singularidad tecnológica por el profesor de Matemáticas y autor de ciencia ficción Vernor Vinge. Good y Vinge señalan correctamente que la curva del progreso tecnológico actualmente está creciendo de manera exponencial . Sin embargo, es un buen paso adelante extrapolar que la curva continuará hacia la singularidad de un crecimiento casi infinito.
</h6>
<h6>
La preocupación y el miedo de Vinge radica en llegar a la singularidad, sin embargo otros científicos y futuristas gozan con esa idea. En el Robot, Mere Machine to Trascendent Mind (Mera máquina hacia la mente trascendente), Hans Moravec predice que los robots se igualarán a la inteligencia humana en 50 años y a continuación la excederán:
</h6>
<h6>
De manera bastante rápida podríamos quedar desplazados y fuera de la existencia. No estoy tan alarmado como muchos otros por esta última posibilidad, ya que considero que las máquinas del futuro son nuestra progenie, «hijos de mente» construidos a nuestra imagen y semejanza, es decir, nosotros mismos pero en una forma más potente. Al igual que los hijos biológicos de generaciones anteriores, representarán la mejor esperanza de la humanidad para un futuro a largo plazo. 
</h6>
<h6>
Existe incluso una palabra nueva, trashumanismo, que se refiere al movimiento social real que ansía este futuro. Basta con decir que estos temas presentan un reto para la mayoría de los teóricos que consideran la preservación de la vida humana y de las especies como algo bueno.
</h6>
<h6>
Finalmente, tomemos en consideración el punto de vista del robot. Si los robots adquieren conciencia, tratarlos entonces como solo “máquinas” podría ser inmoral. Los robots también deben actuar moralmente, necesitaríamos programarlos con una teoría de lo que está bien y lo que está mal.
</h6>
