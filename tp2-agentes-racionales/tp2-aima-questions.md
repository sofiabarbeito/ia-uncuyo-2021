<h3>2.10</h3>
<h5>
a. No, porque no tiene evidencia provista por la secuencia de percepciones y tampoco se incorpora conocimiento en el agente, lo que no puede decidir que accion maximiza la medida de desempeño.
</h5>
<h5>
b. No, porque como el agente se sigue moviendo, se penaliza cada movimiento, entonces no se maximiza la medida de desempeño 
</h5>
<h5>
c. En la a, no es racional porque igualamente no tenemos memoria de que hizo el agente con anterioridad. 
  En la b, si es racional, ya que puede decidir a que casillas ir y parar cuando estén todas limpias.
</h5>
  
<h3>2.11</h3>
<h5>
a. No, porque no tiene evidencia provista por la secuencia de percepciones y tampoco se incorpora conocimiento en el agente, lo que no puede decidir que accion maximiza la medida de desempeño.
</h5>
<h5>  
b. No, lo probamos en las tablas de tp2-results.md. Tiene mejores resultados el Agente Reflexivo Simple.
</h5>
<h5>  
c. Si, para un entorno de 16x16 con porcentaje de suciedad de 0.4, la medida de desempeño es de 47.
</h5>
<h5>  
d. Si, porque gracias al estado interno que tienen, pueden ir guardando conocimientos del mundo, los cuales antes no sabian nada. En cambio los Agentes Reflexivos Simples nunca van a saber nada del entorno.
  
</h5>
